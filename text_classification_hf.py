# -*- coding: utf-8 -*-
"""text_classification_HF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ax4sYdHufavHmNf-jJXhB9PlcuyPYl1M
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# ! pip install transformers datasets evaluate

import sys
print(sys.version)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# from datasets import load_dataset
# imdb = load_dataset("imdb")

print(imdb["train"][0])
print(imdb["test"][0])

print(imdb["train"].shape, imdb["test"].shape)

imdb["train"]

import pandas as pd
X_train = pd.DataFrame(imdb["train"]['text'][:25000]).rename(columns={0: 'text'})
y_train = pd.DataFrame(imdb["train"]['label'][:25000]).rename(columns={0: 'target'})
X_test = pd.DataFrame(imdb["test"]['text'][:25000]).rename(columns={0: 'text'})
y_test = pd.DataFrame(imdb["test"]['label'][:25000]).rename(columns={0: 'target'})
print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)
del(imdb)

n=1000
n_per_label =  (y_train['target'].value_counts()/len(y_train)* n).round().astype(int)
indices_sample = []
for label, count in n_per_label.items():
    # Sélectionner les indices pour chaque label
    label_indices = y_train[y_train['target'] == label].sample(n=count, random_state=42).index
    indices_sample.extend(label_indices)

y_train_spl = y_train.iloc[indices_sample]
X_train_spl = X_train.iloc[indices_sample]

n=250
n_per_label =  (y_test['target'].value_counts()/len(y_test)* n).round().astype(int)
indices_sample = []
for label, count in n_per_label.items():
    # Sélectionner les indices pour chaque label
    label_indices = y_test[y_test['target'] == label].sample(n=count, random_state=42).index
    indices_sample.extend(label_indices)

y_test_spl = y_test.iloc[indices_sample]
X_test_spl = X_test.iloc[indices_sample]

print(y_train_spl.shape, X_train_spl.shape, y_test_spl.shape, X_test_spl.shape)

from datasets import Dataset
df_train = {'text' : X_train_spl.text.tolist(), 'label': y_train_spl.target.tolist()}
df_test = {'text' : X_test_spl.text.tolist(), 'label': y_test_spl.target.tolist()}

df_train = pd.DataFrame(df_train)
df_test = pd.DataFrame(df_test)

ds_train = Dataset.from_pandas(df_train)
ds_test = Dataset.from_pandas(df_test)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# from transformers import AutoTokenizer
# tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased")
# def preprocess_function(examples):
#     return tokenizer(examples["text"], padding="max_length", truncation=True)
# from transformers import DataCollatorWithPadding
# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# tokenized_train = ds_train.map(preprocess_function, batched=True)
# tokenized_test = ds_test.map(preprocess_function, batched=True)

tokenized_train

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# import evaluate
# accuracy = evaluate.load("accuracy")
# 
# import numpy as np
# def compute_metrics(eval_pred):
#     predictions, labels = eval_pred
#     predictions = np.argmax(predictions, axis=1)
#     return accuracy.compute(predictions=predictions, references=labels)

# def compute_metrics(p):
#     predictions, labels = p
#     predictions = torch.argmax(torch.tensor(predictions), axis=1)
#     accuracy = (predictions == labels).sum().item() / len(labels)
#     return {"accuracy": accuracy}

import torch
print(torch.cuda.is_available())
!nvidia-smi

id2label = {0: "NEGATIVE", 1: "POSITIVE"}
label2id = {"NEGATIVE": 0, "POSITIVE": 1}

from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer

# "distilbert-base-uncased"  "huawei-noah/TinyBERT_General_4L_312D"  "albert-base-v2" "facebook/bart-base" "t5-small"
model_name= "distilbert-base-uncased"

model = AutoModelForSequenceClassification.from_pretrained(
    model_name, num_labels=2, id2label=id2label, label2id=label2id
)
total_params = sum(p.numel() for p in model.parameters())
print("Total number of parameters:", f"{total_params:,}".replace(",", " ") )

torch.cuda.empty_cache()
!nvidia-smi --gpu-reset -i 0
#!kill -9 $(pgrep -f 'python')

# Commented out IPython magic to ensure Python compatibility.
# %%time
# from transformers import AdamW, get_scheduler, Adafactor # LAMB,
# from torch.optim import AdamW
# 
# # Commence avec un batch size modéré (8 ou 16) et surveille la mémoire GPU avec nvidia-smi.
# # Si l'utilisation mémoire GPU est faible, augmente la taille du batch pour tirer parti du GPU, mais reste dans les limites de la mémoire.
# # Si l'entraînement devient trop lent, réduis la taille du batch et teste l'effet sur les performances.
# # Si la mémoire est saturée, utilise gradient_accumulation_steps pour simuler un plus grand batch tout en utilisant moins de mémoire.
# torch.cuda.empty_cache() # pour vider le GPU
# 
# training_args = TrainingArguments(
#     output_dir="my_awesome_model",
#     learning_rate=2e-5,
#     per_device_train_batch_size=32,
#     per_device_eval_batch_size=32,
#     gradient_accumulation_steps=16,
#     num_train_epochs=5,
#     weight_decay=0.01,
#     evaluation_strategy="epoch",
#     save_strategy="epoch",
#     load_best_model_at_end=True,
#     push_to_hub=False,
#     report_to='none',
#     fp16=True,
#     logging_dir='./logs',
#     logging_steps=1,
#     logging_first_step=True,
#     save_steps=100
# )
# 
# # Créer un optimiseur AdamW personnalisé
# # optimizer = AdamW(model.parameters(), lr=training_args.learning_rate, weight_decay=training_args.weight_decay)
# # optimizer = LAMB(model.parameters(), lr=training_args.learning_rate, weight_decay=training_args.weight_decay)
# optimizer = Adafactor(model.parameters(), lr=training_args.learning_rate, relative_step=False, weight_decay=training_args.weight_decay)
# 
# trainer = Trainer(
#     model=model,
#     args=training_args,
#     train_dataset=tokenized_train,
#     eval_dataset=tokenized_test,
#     tokenizer=tokenizer,
#     data_collator=data_collator,
#     compute_metrics=compute_metrics,
#     optimizers=(optimizer, None),  # Pas de scheduler personnalisé ici
# )
# 
# trainer.train()

results = trainer.evaluate()
print(results)